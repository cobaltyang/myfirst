{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxRUbjY/wUHD9Ya/K1mP9q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cobaltyang/myfirst/blob/main/yuantpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvZN6WwTUl1b",
        "outputId": "76997596-bee6-4005-ba11-dde2e17a180b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.24.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "zqY1SDVJ1vfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  TPU_ADDRESS = 'grpc://' + device_name\n",
        "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        "  print('TPU not found')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uamT96zxVu7K",
        "outputId": "8a56d1ba-2741-4771-9797-773820274c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found TPU at: grpc://10.14.66.186:8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title My Code\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pwd\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/yuan/yuan')\n",
        "\n",
        "from ghostNet import GhostNet\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import scipy.io as sio\n",
        "import keras\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Reshape, Dropout,ReLU\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# # 启用GPU的内存增长\n",
        "# physical_devices = tf.config.list_physical_devices('GPU')\n",
        "# if physical_devices:\n",
        "#     try:\n",
        "#         tf.config.set_logical_device_configuration(\n",
        "#             physical_devices[0],\n",
        "#             [tf.config.LogicalDeviceConfiguration(memory_limit=7000)])  # 可根据需要设置内存限制\n",
        "#         print(\"GPU memory growth enabled.\")\n",
        "#     except RuntimeError as e:\n",
        "#         print(e)\n",
        "# else:\n",
        "#     print(\"No GPU devices found.\")\n",
        "\n",
        "\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "\n",
        "# ---------------------网络结构搭建------------------------- #\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# 加载数据\n",
        "print('Loading data...')\n",
        "\n",
        "# 划分\n",
        "f = '/content/drive/MyDrive/yuan/yuan/Train_set_.mat'\n",
        "train_set = sio.loadmat(f)  # 导入后的数据是一个字典，取出想要的变量字段即可\n",
        "\n",
        "dim = 16\n",
        "x_train = np.concatenate(\n",
        "    (train_set['R_train_real'].transpose(2, 0, 1).reshape(-1, dim, dim, 1),\n",
        "     train_set['R_train_imag'].transpose(2, 0, 1).reshape(-1, dim, dim, 1)),\n",
        "    axis=3)\n",
        "\n",
        "y_train = np.concatenate(\n",
        "    (train_set['w_train_real'].transpose(2, 0, 1).reshape(-1, dim),\n",
        "     train_set['w_train_imag'].transpose(2, 0, 1).reshape(-1, dim)),\n",
        "    axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 数据打乱\n",
        "index = [i for i in range(x_train.shape[0])]\n",
        "random.shuffle(index)  # shuffle() 方法将序列的所有元素随机排序\n",
        "x_train = x_train[index]\n",
        "y_train = y_train[index]\n",
        "\n",
        "# 创建模型\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "# TEST_SIZE = 0.3     # ImageDataGenerator生成的验证集是前30%个\n",
        "EPOCHS = 10\n",
        "with tpu_strategy.scope():\n",
        "  model = GhostNet((16,16,2)).build()\n",
        "  # model.summary()\n",
        "  tpu_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# 模型编译\n",
        "  model.compile(optimizer=tpu_optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "# 模型断点保存\n",
        "model_checkpoint = ModelCheckpoint('checkpoint/GhostNet-100epoch_my-datasets224_pretrainModel.hdf5', monitor='val_loss',\n",
        "                                   verbose=1, save_best_only=True)\n",
        "\n",
        "model_name = \"GhostNet-my_datasets224-{}\".format(int(time.time()))\n",
        "tensorboard = TensorBoard(log_dir='./tmp/log/{}'.format(model_name),\n",
        "                          histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "EarlyStop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1, mode='auto') # type: ignore\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='auto', verbose=2, min_lr=1e-10, factor=0.5, # type: ignore\n",
        "                                              patience=35) # type: ignore \n",
        "checkpoint = keras.callbacks.ModelCheckpoint('my_model.h5', monitor='val_loss', verbose=0, save_best_only=True, \n",
        "                                             mode='auto') # type: ignore\n",
        "# train\n",
        "with tpu_strategy.scope():\n",
        "  history_cnn = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2, validation_split=0.25)\n",
        "                        # callbacks=[EarlyStop, reduce_lr, checkpoint])\n",
        "\n",
        "\n",
        "# 保存训练的参数\n",
        "model.save_weights(f\"ghostNet_my-{EPOCHS}.h5\")\n",
        "\n",
        "\n",
        "# -----------------------------------可视化模型训练曲线------------------------------- #\n",
        "plt.figure()\n",
        "history_dict = history_cnn.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "# print(history_dict.keys())\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "O0JT2Duqoa3C",
        "outputId": "640d587d-3273-4de7-dabe-41e72b6e9150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n",
            "Tensorflow version: 2.12.0\n",
            "Loading data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6fd24df6878c>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtpu_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_resolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tpu_resolver' is not defined"
          ]
        }
      ]
    }
  ]
}